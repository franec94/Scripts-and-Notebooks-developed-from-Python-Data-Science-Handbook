{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bk1_BP6UdRC3"
   },
   "source": [
    "#### Import Libraries(Python's built-in modules, third party libraries, packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CnVNbk0dWqMm"
   },
   "outputs": [],
   "source": [
    "# Magic statements.\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "# Import graph libraries.\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator, AutoMinorLocator\n",
    "\n",
    "# Import main modules, packages, and third party libraries.\n",
    "import numpy as np; from numpy import nan\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "# Import scikit-learn classes: datasets.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Import scikit-learn classes: preprocessing step utility functions.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA                # Unsupervised Machine Learning tasks: feature reduction, dimensionality reduction\n",
    "from sklearn.mixture import GaussianMixture          # Unsupervised Machine Learning tasks: clustering\n",
    "from sklearn.manifold import Isomap                  # Unsupervised Machine Learning tasks: feature reduction, dimensionality reduction\n",
    "\n",
    "# Import scikit-learn classes: models (Estimators).\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Import scikit-learn classes: preprocessing.\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# from sklearn.preprocessing import Imputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Import scikit-learn classes: Hyperparameters Validation utility functions.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeavePOut\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Import scikit-learn classes: model's evaluation step utility functions.\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jmF5-G5DdXal"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iFPY_33Qdl_q"
   },
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UIm0k40kmL_J"
   },
   "outputs": [],
   "source": [
    "def decorator_timeit(*args_1, **kwargs_1):\n",
    "\n",
    "    def wrapper_timeit(*args_2, **kwargs_2):\n",
    "        timestamp1 = time.time()\n",
    "\n",
    "        args_1[0](kwargs_2)\n",
    "\n",
    "        timestamp2 = time.time()\n",
    "        print(\"This took %.2f seconds\" % (timestamp2 - timestamp1))\n",
    "        pass\n",
    "\n",
    "    return wrapper_timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yZ6E1HO0gNp7"
   },
   "outputs": [],
   "source": [
    "def decorator_run_pipeline_cv(\n",
    "    a_func\n",
    "  ):\n",
    "    \n",
    "    def wrapper_decorator(\n",
    "      model=None, train=None,\n",
    "      test=None, random_state=0, cv=None,\n",
    "    ):\n",
    "        assert model is not None, 'model is None'\n",
    "        assert train is not None, 'train is None'\n",
    "        assert test is not None, 'test is None'\n",
    "    \n",
    "        print('[*] Running pipeline...')\n",
    "\n",
    "        a_func(model, train, test, random_state, cv)\n",
    "    \n",
    "        print('[*] Pipeline done.')\n",
    "        pass\n",
    "\n",
    "    return wrapper_decorator\n",
    "\n",
    "@decorator_run_pipeline_cv\n",
    "def run_pipeline(model, train, test, random_state=0, cv=None):\n",
    "    \n",
    "    # Shuffle data used for training.\n",
    "    Xtrain, ytrain = train.data, train.target\n",
    "    Xtrain, ytrain = shuffle(Xtrain, ytrain, random_state=random_state)\n",
    "\n",
    "    # Shuffle data used for test phase, if any.\n",
    "    Xtest, ytest = test.data, test.target\n",
    "    Xtest, ytest = shuffle(Xtest, ytest, random_state=random_state)\n",
    "\n",
    "    # check whether to perform cv, having provided as input argument\n",
    "    # passed to this function a quantity representing:\n",
    "    # - either, number of folds in which training set will be splitted\n",
    "    # - or, a cross-validation scheme, techique, pattern, represented\n",
    "    #   by means of a Scikit-Learn class object.\n",
    "    if cv is not None:\n",
    "        print('[*] CV running...')\n",
    "        scores = cross_val_score(model, Xtrain, ytrain , cv=cv)\n",
    "        print(scores)\n",
    "        print(scores.mean())\n",
    "        print('[*] CV done.')\n",
    "    \n",
    "    # Fit the model to training data\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    labels = model.predict(Xtest)\n",
    "    \n",
    "    if test is not None:\n",
    "        mat = confusion_matrix(ytest, labels)\n",
    "        sns.heatmap(mat.T, square=True,\n",
    "             annot=True, fmt='d',\n",
    "             cbar=False,\n",
    "             xticklabels=train.target_names, yticklabels=train.target_names, )\n",
    "        plt.xlabel('true label')\n",
    "        plt.ylabel('predicted label')\n",
    "\n",
    "        print('K-Neighbors Classifier accuracy score:', accuracy_score(ytest, labels))\n",
    "        print(f\"K-Neighbors Classifier accuracy score (percentage): {accuracy_score(ytest, labels)*100:.2f}%\")\n",
    "    \n",
    "    def predict_category(s, train=train, model=model):\n",
    "        pred = model.predict([s])\n",
    "        \n",
    "        return ', '.join([ str(pred), str(train.target_names[pred[0]]) ])\n",
    "    \n",
    "    print(predict_category('sending a payload to the ISS'))\n",
    "    print(predict_category('discussing islam versus atheism'))\n",
    "    print(predict_category('determinig screen resolution and size'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OFBE9PStdklq"
   },
   "outputs": [],
   "source": [
    "def decorator_inner_vs_outer_cv(\n",
    "    a_func\n",
    "  ):\n",
    "    def wrapper_decorator(\n",
    "      clf,\n",
    "      Xtrain, ytrain,\n",
    "      param_grid,\n",
    "      Xtest, ytest,\n",
    "      num_trials=30,\n",
    "      random_state=0,\n",
    "      verbose=0,\n",
    "    ):\n",
    "\n",
    "        assert clf is not None, 'cls is None'\n",
    "        assert train is not None, 'train is None'\n",
    "        assert param_grid is not None, 'param_grid is None'\n",
    "\n",
    "        print('[*] inner_vs_outer_cv running...')\n",
    "        a_func(\n",
    "          clf,\n",
    "          Xtrain, ytrain,\n",
    "          param_grid,\n",
    "          Xtest, ytest,\n",
    "          test=None,\n",
    "          num_trials=30,\n",
    "          random_state=0,\n",
    "          verbose=0\n",
    "        )\n",
    "        print('[*] inner_vs_outer_cv done.')\n",
    "        pass\n",
    "    return wrapper_decorator\n",
    "\n",
    "@decorator_inner_vs_outer_cv\n",
    "def inner_vs_outer_cv(\n",
    "    clf,\n",
    "    Xtrain, ytrain,\n",
    "    param_grid,\n",
    "    Xtest, ytest,\n",
    "    test=None,\n",
    "    num_trials=30,\n",
    "    random_state=0,\n",
    "    verbose=0):\n",
    "  \n",
    "    Xtrain, ytrain = shuffle(Xtrain, ytrain, random_state=random_state)\n",
    "\n",
    "    if Xtest is not None and ytest is not None:\n",
    "        Xtest, ytest = shuffle(Xtest, ytest, random_state=random_state)\n",
    "\n",
    "    # Arrays to store scores\n",
    "    non_nested_scores = np.zeros(num_trials)\n",
    "    nested_scores = np.zeros(num_trials)\n",
    "\n",
    "    # Loop for each trial\n",
    "    for i in range(num_trials):\n",
    "        # Choose cross-validation techniques for the inner and outer loops,\n",
    "        # independently of the dataset.\n",
    "        # E.g \"GroupKFold\", \"LeaveOneOut\", \"LeaveOneGroupOut\", etc.\n",
    "        inner_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "        outer_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "\n",
    "        # Non_nested parameter search and scoring\n",
    "        clf = GridSearchCV(estimator=clf, param_grid=param_grid, cv=inner_cv)\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        non_nested_scores[i] = clf.best_score_\n",
    "\n",
    "        # Nested CV with parameter optimization\n",
    "        nested_score = cross_val_score(clf, X=Xtrain, y=ytrain, cv=outer_cv)\n",
    "        nested_scores[i] = nested_score.mean()\n",
    "\n",
    "    score_difference = non_nested_scores - nested_scores\n",
    "\n",
    "    print(\"Average difference of {:6f} with std. dev. of {:6f}.\"\n",
    "        .format(score_difference.mean(), score_difference.std()))\n",
    "\n",
    "    # Plot scores on each trial for nested and non-nested CV\n",
    "    plt.figure()\n",
    "    plt.subplot(211)\n",
    "    non_nested_scores_line, = plt.plot(non_nested_scores, color='r')\n",
    "    nested_line, = plt.plot(nested_scores, color='b')\n",
    "    plt.ylabel(\"score\", fontsize=\"14\")\n",
    "    plt.legend([non_nested_scores_line, nested_line],\n",
    "             [\"Non-Nested CV\", \"Nested CV\"],\n",
    "            bbox_to_anchor=(0, .4, .5, 0))\n",
    "    plt.title(\"Non-Nested and Nested Cross Validation on Iris Dataset\",\n",
    "            x=.5, y=1.1, fontsize=\"15\")\n",
    "\n",
    "    # Plot bar chart of the difference.\n",
    "    plt.subplot(212)\n",
    "    difference_plot = plt.bar(range(NUM_TRIALS), score_difference)\n",
    "    plt.xlabel(\"Individual Trial #\")\n",
    "    plt.legend([difference_plot],\n",
    "           [\"Non-Nested CV - Nested CV Score\"],\n",
    "           bbox_to_anchor=(0, 1, .8, 0))\n",
    "    plt.ylabel(\"score difference\", fontsize=\"14\")\n",
    "\n",
    "    plt.show()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S40MG9CCfgSs"
   },
   "outputs": [],
   "source": [
    "def shuffle_data_and_show_some_info(features, target):\n",
    "    features, target = shuffle(features, target, random_state=0)\n",
    "    \n",
    "    print('samples type:', type(features))\n",
    "    print('target type:', type(target))\n",
    "\n",
    "    print('samples size:', len(features))\n",
    "    print('target size:', target.shape)\n",
    "\n",
    "    return features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rVxGRZHadaLV"
   },
   "outputs": [],
   "source": [
    "# Global starting variables.\n",
    "SEED = 42\n",
    "RANDOM_STATE = 1\n",
    "NUM_TRIALS = 2\n",
    "\n",
    "# Instantiate, or create, a random generator object.\n",
    "rng = np.random.RandomState(seed=SEED)\n",
    "\n",
    "# Set seed for numpy module.\n",
    "np.random.seed(seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h6nevLl-fWpN"
   },
   "source": [
    "#### Load 20-News Groups Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "Gc8ztmx1e44P",
    "outputId": "918a52cc-8755-48a8-f429-fcf9a9f2d397"
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "categories = [\n",
    "    'talk.religion.misc',\n",
    "    'soc.religion.christian',\n",
    "    'sci.space',\n",
    "    'comp.graphics',\n",
    "]\n",
    "\n",
    "train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "pprint(list(newsgroups_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "uYWzDR_kf43J",
    "outputId": "6adda5a4-2d11-49ef-8e8c-e527af007697"
   },
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "Xtrain, ytrain = train.data, train.target\n",
    "Xtrain, ytrain = shuffle_data_and_show_some_info(Xtrain, ytrain)\n",
    "\n",
    "Xtest, ytest = test.data, test.target\n",
    "Xtest, ytest = shuffle_data_and_show_some_info(Xtest, ytest)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 511
    },
    "colab_type": "code",
    "id": "PzkYkOvahGVq",
    "outputId": "bbc84525-779a-4311-ed85-9f961a6436d3"
   },
   "outputs": [],
   "source": [
    "# Run pipeline for:\n",
    "# 1. Feature Engeneerint technique: TfidfVectorizer\n",
    "# 2. Estimator: MultinomialNB\n",
    "\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "run_pipeline(model, train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zLq1y8ZdljyO"
   },
   "source": [
    "#### Grid-Search | CV | TfidfVectorizer | Multicategory Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qw5-9YYTh_To",
    "outputId": "3f76aee2-51f3-4f30-ccdb-5f44a472f33c"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'penalty': ['l2'],                                # ['l1', 'l2', 'elastic', 'none'],\n",
    "    'multi_class': ['multinomial', 'ovr'],\n",
    "    'C': [0.001, 0.01, 0.1, 1.0],\n",
    "    'solver':['newton-cg', 'lbfgs', 'sag', 'saga',],  # ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga',],\n",
    "}\n",
    "\n",
    "lrm = LogisticRegression()\n",
    "\n",
    "Xtrain, ytrain = train.data, train.target\n",
    "Xtest, ytest = test.data, test.target\n",
    "\n",
    "# Xtrain, ytrain = shuffle(Xtrain, ytrain, random_state=RANDOM_STATE)\n",
    "# Xtest, ytest = shuffle(Xtest, ytest, random_state=RANDOM_STATE)\n",
    "\n",
    "# Vectorize training set data \n",
    "vec = TfidfVectorizer()\n",
    "vec.fit(Xtrain)\n",
    "\n",
    "Xtrain = vec.transform(Xtrain)\n",
    "Xtest = vec.transform(Xtest)\n",
    "\n",
    "assert inner_vs_outer_cv is not None, 'inner_vs_outer_cv is None'\n",
    "\n",
    "inner_vs_outer_cv( \n",
    "    clf=lrm,\n",
    "    Xtrain=Xtrain, ytrain=ytrain,\n",
    "    param_grid=param_grid,\n",
    "    Xtest=Xtest, ytest=ytest,\n",
    "    num_trials=NUM_TRIALS,\n",
    "    random_state=RANDOM_STATE,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Y-YgQHUlVTs"
   },
   "source": [
    "#### Grid-Search | CV | CountVectorizer | Multicategory Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ljxNd03dkigv"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'penalty': ['l2'],                                # ['l1', 'l2', 'elastic', 'none'],\n",
    "    'multi_class': ['multinomial', 'ovr'],\n",
    "    'C': [0.001, 0.01, 0.1, 1.0],\n",
    "    'solver':['newton-cg', 'lbfgs', 'sag', 'saga',],  # ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga',],\n",
    "}\n",
    "\n",
    "lrm = LogisticRegression()\n",
    "\n",
    "Xtrain, ytrain = train.data, train.target\n",
    "Xtest, ytest = test.data, test.target\n",
    "\n",
    "# Xtrain, ytrain = shuffle(Xtrain, ytrain, random_state=RANDOM_STATE)\n",
    "# Xtest, ytest = shuffle(Xtest, ytest, random_state=RANDOM_STATE)\n",
    "\n",
    "# Vectorize training set data \n",
    "vec = CountVectorizer()\n",
    "vec.fit(Xtrain)\n",
    "\n",
    "Xtrain = vec.transform(Xtrain)\n",
    "Xtest = vec.transform(Xtest)\n",
    "\n",
    "assert inner_vs_outer_cv is not None, 'inner_vs_outer_cv is None'\n",
    "\n",
    "inner_vs_outer_cv( \n",
    "    clf=lrm,\n",
    "    Xtrain=Xtrain, ytrain=ytrain,\n",
    "    param_grid=param_grid,\n",
    "    Xtest=Xtest, ytest=ytest,\n",
    "    num_trials=NUM_TRIALS,\n",
    "    random_state=RANDOM_STATE,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fc0m7ua1kjEY"
   },
   "source": [
    "#### References\n",
    "- (The 20 newsgroups text dataset) https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html\n",
    "\n",
    "- Logistic Regression technique, classifier, estimator:\n",
    "    - (Constructor) https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "    - (Example) https://scikit-learn.org/stable/auto_examples/linear_model/plot_logistic_multinomial.html#sphx-glr-auto-examples-linear-model-plot-logistic-multinomial-py\n",
    "- (Shuffle) https://scikit-learn.org/stable/modules/generated/sklearn.utils.shuffle.html\n",
    "\n",
    "- Python language topics:\n",
    "  - (**kwargs) https://www.geeksforgeeks.org/args-kwargs-python/\n",
    "\n",
    "- Books:\n",
    "    - https://www.amazon.com/Data-Science-Press-Essential-Knowledge-ebook/dp/B07C4HKQ9N/ref=pd_sim_351_45?_encoding=UTF8&pd_rd_i=B07C4HKQ9N&pd_rd_r=5596dff3-2c3b-4da1-8ee0-d3cc545795b0&pd_rd_w=mYFPa&pd_rd_wg=PpSaM&pf_rd_p=bab57536-7c8f-4781-a8ed-3e270b9cd303&pf_rd_r=RZE20M87BBFMMNWVZDSD&psc=1&refRID=RZE20M87BBFMMNWVZDSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "bk1_BP6UdRC3",
    "h6nevLl-fWpN"
   ],
   "name": "template_inner_vs_outer_cv.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
