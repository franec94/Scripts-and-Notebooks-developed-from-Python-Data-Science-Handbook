{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules, Packages and Third Party Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic statements.\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Import graph libraries.\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator, AutoMinorLocator\n",
    "\n",
    "# Import main modules, packages, and third party libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()\n",
    "import sklearn\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Import scikit-learn classes: datasets.\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Import scikit-learn classes: preprocessing step utility functions.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA # Unsupervised Machine Learning tasks: feature reduction, dimensionality reduction\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.mixture import GaussianMixture # Unsupervised Machine Learning tasks: clustering\n",
    "from sklearn.manifold import Isomap # Unsupervised Machine Learning tasks: feature reduction, dimensionality reduction\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Import scikit-learn classes: models (Estimators).\n",
    "from sklearn.naive_bayes import GaussianNB           # Non-parametric Generative Model\n",
    "from sklearn.naive_bayes import MultinomialNB        # Non-parametric Generative Model\n",
    "from sklearn.linear_model import LinearRegression    # Parametric Linear Discriminative Model\n",
    "from sklearn.linear_model import LogisticRegression  # Parametric Linear Discriminative Model\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC                          # Parametric Linear Discriminative \"Support Vector Classifier\"\n",
    "from sklearn.tree import DecisionTreeClassifier      # Non-parametric Model\n",
    "from sklearn.ensemble import BaggingClassifier       # Non-parametric Model (Meta-Estimator, that is, an Ensemble Method)\n",
    "from sklearn.ensemble import RandomForestClassifier  # Non-parametric Model (Meta-Estimator, that is, an Ensemble Method)\n",
    "\n",
    "# Import scikit-learn classes: Pipeline utility functions.\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Import scikit-learn classes: Hyperparameters Validation utility functions.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeavePOut\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# Import scikit-learn classes: model's evaluation step utility functions.\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "# from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.load_pittburgh_dataset import load_brdiges_dataset\n",
    "\n",
    "# === UTILS IMPORTS (Done by myself) ==== #\n",
    "from utils.display_utils import display_heatmap\n",
    "from utils.display_utils import show_frequency_distribution_predictors\n",
    "from utils.display_utils import show_categorical_predictor_values\n",
    "from utils.display_utils import  show_cum_variance_vs_components\n",
    "\n",
    "from utils.preprocessing_utils import preprocess_categorical_variables\n",
    "from utils.preprocessing_utils import  preprocessing_data_rescaling\n",
    "\n",
    "from utils.training_utils import sgd_classifier_grid_search\n",
    "from utils.training_utils import naive_bayes_classifier_grid_search\n",
    "from utils.training_utils import svm_linear_classifier_grid_search\n",
    "from utils.training_utils import decision_tree_classifier_grid_search\n",
    "from utils.training_utils import random_forest_classifier_grid_search\n",
    "from utils.training_utils import plot_roc_crossval\n",
    "from utils.training_utils import fit_by_n_components\n",
    "\n",
    "from utils.training_utils import kfold_cross_validation\n",
    "from utils.training_utils import loo_cross_validation\n",
    "from utils.training_utils import fit\n",
    "from utils.training_utils import grid_search_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global starting variables.\n",
    "seed = 42\n",
    "random_state = 1\n",
    "target_col = 'T-OR-D' # 'T-OR-D' | 'CLEAR-G'\n",
    "\n",
    "# Instantiate, or create, a random generator object.\n",
    "rng = np.random.RandomState(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration & Investigation Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === READ INPUT DATASET ==== #\n",
    "dataset = load_brdiges_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics & Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(dataset, hue=target_col, size=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_2_avoid = ['ERECTED', 'LENGTH', 'LOCATION']\n",
    "# show_frequency_distribution_predictors(dataset, columns_2_avoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_result = dataset.corr()\n",
    "# display_heatmap(corr_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = dataset.columns\n",
    "# target_col = 'T-OR-D'\n",
    "\n",
    "y = np.array(list(map(lambda x: 0 if x == 1 else 1, dataset[target_col].values)), dtype=int)\n",
    "print(dataset[target_col].value_counts())\n",
    "X = dataset.loc[:, dataset.columns != target_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()           # 2. Instantiate the model w/ hyperparameters.\n",
    "model.fit(Xtrain, ytrain)      # 3. Fit the model to data. Notice y is not specified.          \n",
    "\n",
    "y_model = model.predict(Xtest) # 4. Predict sample's class labels\n",
    "print('Gaussian naive Bayes accuracy score:', accuracy_score(ytest, y_model))\n",
    "print(f\"Gaussian naive Bayes accuracy score (percentage): {accuracy_score(ytest, y_model)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = confusion_matrix(ytest, y_model)\n",
    "\n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "scores = cross_val_score(clf, Xtrain, ytrain, cv=loo)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "for cv in [3,4,5,10]:\n",
    "    scores = cross_val_score(clf, Xtrain, ytrain, cv=cv)\n",
    "    print(\"CV=%d | Accuracy: %0.2f (+/- %0.2f)\" % (cv, scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(Xtrain, ytrain)\n",
    "y_model = clf.predict(Xtest) # 4. Predict sample's class labels\n",
    "print('Gaussian naive Bayes accuracy score:', accuracy_score(ytest, y_model))\n",
    "print(f\"Gaussian naive Bayes accuracy score (percentage): {accuracy_score(ytest, y_model)*100:.2f}%\")\n",
    "\n",
    "mat = confusion_matrix(ytest, y_model)\n",
    "\n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=random_state)\n",
    "\n",
    "clf = GaussianNB()\n",
    "kfold_cross_validation(clf, Xtrain, ytrain)\n",
    "\n",
    "clf = GaussianNB()\n",
    "loo_cross_validation(clf, Xtrain, ytrain)\n",
    "\n",
    "clf = GaussianNB()\n",
    "fit(clf, Xtrain, ytrain, Xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal Component Analysis (PCA) for Unsupervied Machine Learning Tasks: Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PCA(n_components=2)    # 2. Instantiate model with hyperparameters\n",
    "model.fit(X)              # 3. Fit to data. Notice y is not specified\n",
    "X_2D = model.transform(X) # 4. Transform the data to two dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['PCA1'] = X_2D[:, 0]\n",
    "dataset['PCA2'] = X_2D[:, 1]\n",
    "\n",
    "sns.lmplot(\"PCA1\", \"PCA2\", hue=target_col, data=dataset, fit_reg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=random_state)\n",
    "\n",
    "pca = PCA(n_components=2)    # 2. Instantiate model with hyperparameters\n",
    "pca.fit(Xtrain)              # 3. Fit to data. Notice y is not specified\n",
    "Xtrain_transformed = pca.transform(Xtrain) # 4. Transform the data to two dimensional\n",
    "Xtest_transformed = pca.transform(Xtest) # 4. Transform the data to two dimensional\n",
    "\n",
    "clf = GaussianNB()\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "scores = cross_val_score(clf, Xtrain_transformed, ytrain, cv=3)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=random_state)\n",
    "\n",
    "pca = PCA(n_components=2)    # 2. Instantiate model with hyperparameters\n",
    "pca.fit(Xtrain)              # 3. Fit to data. Notice y is not specified\n",
    "Xtrain_transformed = pca.transform(Xtrain) # 4. Transform the data to two dimensional\n",
    "Xtest_transformed = pca.transform(Xtest) # 4. Transform the data to two dimensional\n",
    "\n",
    "clf = GaussianNB()\n",
    "\n",
    "for cv in [3,4,5,10]:\n",
    "    scores = cross_val_score(clf, Xtrain_transformed, ytrain, cv=cv)\n",
    "    print(\"CV=%d | Accuracy: %0.2f (+/- %0.2f)\" % (cv, scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=random_state)\n",
    "\n",
    "pca = PCA(n_components=2)    # 2. Instantiate model with hyperparameters\n",
    "pca.fit(Xtrain)              # 3. Fit to data. Notice y is not specified\n",
    "\n",
    "Xtrain_transformed = pca.transform(Xtrain) # 4. Transform the data to two dimensional\n",
    "Xtest_transformed = pca.transform(Xtest) # 4. Transform the data to two dimensional\n",
    "\n",
    "clf.fit(Xtrain_transformed, ytrain)\n",
    "y_model = clf.predict(Xtest_transformed) # 4. Predict sample's class labels\n",
    "print('Gaussian naive Bayes accuracy score:', accuracy_score(ytest, y_model))\n",
    "print(f\"Gaussian naive Bayes accuracy score (percentage): {accuracy_score(ytest, y_model)*100:.2f}%\")\n",
    "\n",
    "mat = confusion_matrix(ytest, y_model)\n",
    "\n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=random_state)\n",
    "\n",
    "pca = PCA(n_components=2)    # 2. Instantiate model with hyperparameters\n",
    "pca.fit(Xtrain)              # 3. Fit to data. Notice y is not specified\n",
    "\n",
    "Xtrain_transformed = pca.transform(Xtrain) # 4. Transform the data to two dimensional\n",
    "Xtest_transformed = pca.transform(Xtest) # 4. Transform the data to two dimensional\n",
    "\n",
    "clf = GaussianNB()\n",
    "kfold_cross_validation(clf, Xtrain, ytrain)\n",
    "\n",
    "clf = GaussianNB()\n",
    "loo_cross_validation(clf, Xtrain, ytrain)\n",
    "\n",
    "clf = GaussianNB()\n",
    "fit(clf, Xtrain, ytrain, Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KernelPCA(n_components=2, \\\n",
    "                  kernel='rbf')          \n",
    "model.fit(X)                      \n",
    "X_2D = model.transform(X)         \n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X_2D, y, random_state=random_state)\n",
    "\n",
    "clf = GaussianNB()\n",
    "kfold_cross_validation(clf, Xtrain, ytrain)\n",
    "\n",
    "clf = GaussianNB()\n",
    "loo_cross_validation(clf, Xtrain, ytrain)\n",
    "\n",
    "clf = GaussianNB()\n",
    "fit(clf, Xtrain, ytrain, Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_by_n_components(\n",
    "    estimator=GaussianNB(), \\\n",
    "    X=X, \\\n",
    "    y=y, \\\n",
    "    n_components=12, \\\n",
    "    clf_type='GaussianNB', \\\n",
    "    show_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_by_n_components(\n",
    "    estimator=LogisticRegression(), \\\n",
    "    X=X, \\\n",
    "    y=y, \\\n",
    "    n_components=12, \\\n",
    "    clf_type='LogisticRegression', \\\n",
    "    show_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_by_n_components(\n",
    "    estimator=KNeighborsClassifier(), \\\n",
    "    X=X, \\\n",
    "    y=y, \\\n",
    "    n_components=12, \\\n",
    "    clf_type='KNeighborsClassifier', \\\n",
    "    show_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_by_n_components(\n",
    "    estimator=SVC(), \\\n",
    "    X=X, \\\n",
    "    y=y, \\\n",
    "    n_components=12, \\\n",
    "    clf_type='SVC', \\\n",
    "    show_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_by_n_components(\n",
    "    estimator=DecisionTreeClassifier(), \\\n",
    "    X=X, \\\n",
    "    y=y, \\\n",
    "    n_components=12, \\\n",
    "    clf_type='DecisionTreeClassifier', \\\n",
    "    show_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_by_n_components(\n",
    "    estimator=RandomForestClassifier(), \\\n",
    "    X=X, \\\n",
    "    y=y, \\\n",
    "    n_components=12, \\\n",
    "    clf_type='RandomForestClassifier', \\\n",
    "    show_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50,] ,  # [50, 100, 200, 300,],\n",
    "    'criterion':  ['gini',], # ['gini','entropy'],\n",
    "    'max_depth': [None,], # [None, 2, 5, 10],\n",
    "    'n_jobs': [3],\n",
    "    'max_features': [None,], # [int, float, None, 'sqrt', 'log2'],\n",
    "    'bootstrap': [True,] # [True, False]\n",
    "}\n",
    "estimator = RandomForestClassifier()\n",
    "\n",
    "grid_search_estimator(\n",
    "    estimator=estimator,\n",
    "    param_grid=param_grid,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    n_components=7,\n",
    "    clf_type='RandomForestClassifier',\n",
    "    random_state=0, show_plots=False, show_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "#### Scikit-Learn Examples\n",
    "\n",
    "- (Feature transformations with ensembles of trees) https://scikit-learn.org/stable/auto_examples/ensemble/plot_feature_transformation.html#sphx-glr-auto-examples-ensemble-plot-feature-transformation-py\n",
    "- (Receiver Operating Characteristic (ROC) with cross validation) https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py\n",
    "- (Model selection with Probabilistic PCA and Factor Analysis (FA) https://scikit-learn.org/stable/auto_examples/decomposition/plot_pca_vs_fa_model_selection.html#sphx-glr-auto-examples-decomposition-plot-pca-vs-fa-model-selection-py\n",
    "- (ROC Curve with Visualization API) https://scikit-learn.org/stable/auto_examples/plot_roc_curve_visualization_api.html#sphx-glr-auto-examples-plot-roc-curve-visualization-api-py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
